{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Classification with the German Traffic Sign Recognition Benchmark\n",
    "\n",
    "<img src=\"img/sv_pp_TrafficSignRecognition.jpg\" align=\"right\" width=200>\n",
    "An automatic road sign recognition system first locates road signs within images captured by an imaging sensor on-board of a vehicle, and then identifies road signs assisting the driver to properly operate the vehicle.\n",
    "\n",
    "Automated road sign recognition is a difficult task. There are a number of important issues that need to be taken into consideration. These include: illumination conditions, direction of sign's face, status of paint on signs, placement of multiple signs near each other, torn and tilted signs, variations in sign's scale, obstacles such as tree, image sensor's properties, car vibrations, etc. \n",
    "\n",
    "Assuming that the road sign has been previously located in the image, neural networks may be employed to implement the classification module because they have proven to be good classifiers and have been able to successfully solve several object recognition problems. \n",
    "\n",
    "In this notebook you will work on a classification task of several road signs with neural networks. The images will be obtained from [a large, lifelike database of traffic sign images: the German Traffic Sign Recognition Benchmark](http://benchmark.ini.rub.de/?section=gtsrb&subsection=news)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data and preprocessing\n",
    "\n",
    "The German Traffic Sign Benchmark is a multi-class, single-image classification challenge, with the following properties:\n",
    "\n",
    "* Single-image, multi-class classification problem\n",
    "* More than 40 classes\n",
    "* More than 50,000 images in total\n",
    "* Large, lifelike database\n",
    "\n",
    "The training set archive is structured as follows:\n",
    "\n",
    "* One directory per class\n",
    "* Each directory contains one CSV file with annotations (\"GT-<ClassID>.csv\") and the training images\n",
    "* Training images are grouped by tracks\n",
    "* Each track contains 30 images of one single physical traffic sign\n",
    "\n",
    "The following pictures show examples of four different signs, along with their label or class number:\n",
    "\n",
    "<table>\n",
    "<tr>\n",
    "<td><img src=\"img/00004_00022.png\"></td>\n",
    "<td><img src=\"img/00012_00026.png\"></td>\n",
    "<td><img src=\"img/00010_00016.png\"></td>\n",
    "<td><img src=\"img/00003_00009.png\"></td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>00003</td>\n",
    "<td>00007</td>\n",
    "<td>00013</td>\n",
    "<td>00014</td>\n",
    "</tr>\n",
    "</table>\n",
    "\n",
    "**The dataset can be downloaded from [here](http://benchmark.ini.rub.de/Dataset/GTSRB_Final_Training_Images.zip). Please save and decompress the archive in the notebooks folder.**\n",
    "\n",
    "The image directories will be decompressed in a folder named <tt>GTRSB/Final_Training/Images</tt>. \n",
    "\n",
    "The images are PPM images (RGB color). Files are numbered in two parts:\n",
    "\n",
    "    XXXXX_YYYYY.ppm\n",
    "\n",
    "The first part, `XXXXX`, represents the track number. The second part, `YYYYY`, is a running number within the track.\n",
    "\n",
    "The annotations are stored in CSV format (field separator is \";\" (semicolon) ). The annotations contain meta information about the image and the class:\n",
    "\n",
    "* Filename - Image file the following information applies to\n",
    "* Width, Height - Dimensions of the image\n",
    "* Roi.x1,Roi.y1, Roi.x2,Roi.y2 - Location of the sign within the image (Images contain a border around the actual sign of 10 percent of the sign size, at least 5 pixel)\n",
    "* ClassId - The class of the traffic sign\n",
    "\n",
    "The helper function <tt>readTrafficSigns</tt> must be used for reading the images, with the following arguments:\n",
    "* path to the image directories\n",
    "* list of the classes to be read\n",
    "* dictionary with pairs (class, tuple of tracks)\n",
    "\n",
    "The results of the function are:\n",
    "* list of images\n",
    "* list of dimensions\n",
    "* list of ROIs\n",
    "* list of labels\n",
    "* list of filenames\n",
    "\n",
    "The following code uses the function for reading two tracks of each of four classes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from packages.gtrsb import readTrafficSigns\n",
    "\n",
    "classes = [3, 7, 13, 14]\n",
    "tracks = {3: (5, 10), 7: (40, 8), 13: (24, 6), 14: (8, 15)}\n",
    "trainImages, trainDims, trainROIs, \\\n",
    "trainLabels, filenames = readTrafficSigns('./GTSRB/Final_Training/Images', classes, tracks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The number of read images should be: 4 classes &times; 2 tracks/class &times; 30 images/track = 240 images "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(trainImages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image processing\n",
    "\n",
    "Please notice the following information about images:\n",
    "\n",
    "* The images contain one traffic sign each\n",
    "* Images contain a border of 10 % around the actual traffic sign (at least 5 pixels) to allow for edge-based approaches\n",
    "* Image sizes vary between 15x15 to 250x250 pixels\n",
    "* Images are not necessarily squared\n",
    "* The actual traffic sign is not necessarily centered within the image.This is true for images that were close to the image border in the full camera image\n",
    "\n",
    "<img src=\"img/GT-Example.png\" align=\"right\" width=100>\n",
    "The ROI is defined as:\n",
    "* `ROI.x1`: X-coordinate of top-left corner of traffic sign bounding box\n",
    "* `ROI.y1`: Y-coordinate of top-left corner of traffic sign bounding box\n",
    "* `ROI.x2`: X-coordinate of bottom-right corner of traffic sign bounding box\n",
    "* `ROI.y2`: Y-coordinate of bottom-right corner of traffic sign bounding box\n",
    "\n",
    "Let's plot a sample image, e.g. the one with index 100 in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from packages.gtrsb import processImage, plotTrafficSign\n",
    "\n",
    "i = 100\n",
    "roi = trainROIs[i]\n",
    "p1, p2 = roi\n",
    "x1, y1 = p1\n",
    "x2, y2 = p2\n",
    "plt.imshow(trainImages[i])\n",
    "plt.plot([x1,x2,x2,x1,x1],[y1,y1,y2,y2,y1],'c');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The pixels of the image will be the inputs of the neural network. But the number of inputs is constant, thus all the images in the dataset must be scaled to the same resolution.\n",
    "\n",
    "Moreover, the number of inputs has a significant input on the cost of training. A compromise is needed, by keeping the resolution low while still making possible the distinction of road signs.\n",
    "\n",
    "In the processing function, the default image size is set to 20x20 pixels:\n",
    "\n",
    "```def processImage(img, roi, dx=20, dy=20):\n",
    "```\n",
    "\n",
    "In addition, the original images are stored in RGB format, that is, each images has three pixel planes (one for each component). In the image processing, only the red channel is used (i.e. a single plane), since it seems to contain the most interesting information about the road sign.\n",
    "\n",
    "In summary, the image processing steps are:\n",
    "\n",
    "* Crop the image, i.e. select only the part of the image inside the ROI\n",
    "* Scale the image to a fixed, small resultion\n",
    "* Select the red channel\n",
    "* Adjust the contrast with histogram equalization\n",
    "* Finally, normalize the pixel values to the interval [-1,+1]\n",
    "\n",
    "The result of the image processing for the traffic sign above would be:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pr_img = processImage(trainImages[i],trainROIs[i])\n",
    "plt.imshow(pr_img, cmap='gray');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below plots each step of the image processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "img = trainImages[i]\n",
    "roi = trainROIs[i]\n",
    "plotTrafficSign(img, roi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Workshop\n",
    "\n",
    "Your task begins here. You must create a notebook with all the necessary statements for solving the traffic sign classification problem.\n",
    "\n",
    "## Build the dataset\n",
    "\n",
    "You should build a dataset of at least 4 classes with at least 5 tracks on each class. In the notebook, you should read the files, process the images (with the helper functions) and build the data structures.\n",
    "\n",
    "For the maximum grade, your dataset should consist of at least 10 classes with at least 15 tracks on each class.\n",
    "\n",
    "## Build the model and train\n",
    "\n",
    "You should build a multilayer perceptron for learning this classification task. As a starting point, you could try a network similar to the digits problem.\n",
    "\n",
    "You should save the resulting network in a <tt>pkl</tt> file for uploading.\n",
    "\n",
    "You should also include some cells for loading the network and analysing the results without need of training.\n",
    "\n",
    "### Analysis of the network\n",
    "\n",
    "Finally, include the functions for the analysis of the result.\n",
    "\n",
    "#### Classification report\n",
    "\n",
    "#### Confusion matrix\n",
    "\n",
    "#### Loss curve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Workshop\n",
    "**REMEMBER**: for the **workshop of sessions 2-3** you will submit the <tt>pkl</tt> file for the neural network that solves the traffic sign problem, and the <tt>ipynb</tt> file. "
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
