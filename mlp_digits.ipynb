{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recognizing hand-written digits\n",
    "\n",
    "An example showing how the scikit-learn can be used to recognize images of hand-written digits.\n",
    "\n",
    "This example is commented in the [tutorial section of the user manual](http://scikit-learn.org/stable/tutorial/basic/tutorial.html#introduction)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import datasets, metrics\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The digits dataset\n",
    "\n",
    "The data that we are interested in is a set of 1797 images of digits, each one made of $8\\times8$ pixels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "digits = datasets.load_digits()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a look at the first 8 images, stored in the `images` attribute of the\n",
    "dataset. Note that each image must have the same size. For these\n",
    "images, we know which digit they represent: it is given in the `target` of\n",
    "the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "images_and_labels = list(zip(digits.images, digits.target))\n",
    "for index, (image, label) in enumerate(images_and_labels[:8]):\n",
    "    plt.subplot(2, 4, index + 1)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(image, cmap=plt.cm.gray_r, interpolation='nearest')\n",
    "    plt.title('Training: %i' % label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To apply a classifier on this data, we need to flatten the image, to\n",
    "turn the data in a (samples, feature) matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_samples = len(digits.images)\n",
    "data = digits.images.reshape((n_samples, -1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example, the data corresponding to the image of the \"0\" above is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each pixel is a 4-bit value, from 0 (white) to 15 (black)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-validation: evaluating network performance\n",
    "\n",
    "Learning the parameters of the MLP and testing it on the same data is a methodological mistake: a model that would just repeat the labels of the samples that it has just seen would have a perfect score but would fail to predict anything useful on yet-unseen data. This situation is called [**overfitting**](https://en.wikipedia.org/wiki/Overfitting). To avoid it, it is common practice  to hold out part of the available data as a test set `[X_test, y_test]`. \n",
    "\n",
    "In scikit-learn a random split into training and test sets can be quickly computed with the [`train_test_split`](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html#sklearn.model_selection.train_test_split) helper function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X, y = data, digits.target\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data scaling\n",
    "\n",
    "Standardization of datasets is a common requirement for neural networks; they might behave badly if the individual features do not more or less look like standard normally distributed data: Gaussian with zero mean and unit variance.\n",
    "\n",
    "In scikit-learn, the preprocessing module provides a utility class [StandardScaler](http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html#sklearn.preprocessing.StandardScaler) that computes the mean and standard deviation on a training set so as to be able to later reapply the same transformation on the testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Don't cheat - fit only on training data\n",
    "scaler = StandardScaler().fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "# apply same transformation to test data\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the model\n",
    "\n",
    "Create a [MLP object](http://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html) with the following arguments:\n",
    "* [stochastic gradient descent](https://en.wikipedia.org/wiki/Stochastic_gradient_descent) solver (standard technique in [backpropagation](https://en.wikipedia.org/wiki/Backpropagation))\n",
    "* one hidden layer with 5 neurons\n",
    "* 4000 iterations maximum\n",
    "\n",
    "The rest of the arguments are set to their default values (see documentation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "net = MLPClassifier(solver='sgd',\\\n",
    "                    hidden_layer_sizes=(5, ),\\\n",
    "                    max_iter=4000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the network\n",
    "\n",
    "The `fit` function automatically iterates until convergence or the maximum number of iterations is reached, so you only need to execute the following cell once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "net.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis of the network\n",
    "\n",
    "In scikit-learn there are some functions for measuring the accuracy of the classification.\n",
    "\n",
    "### Classification report\n",
    "\n",
    "The [classification_report](http://scikit-learn.org/stable/modules/model_evaluation.html#classification-report) function builds a text report showing the main classification metrics:\n",
    "\n",
    "* [precision](https://en.wikipedia.org/wiki/Precision_and_recall): ratio $\\frac{tp}{tp + fp}$ where $tp$ is the number of true positives and $fp$ the number of false positives. The precision is intuitively the ability of the classifier not to label as positive a sample that is negative.\n",
    "* [recall](https://en.wikipedia.org/wiki/Precision_and_recall): ratio $\\frac{tp}{tp + fn}$ where $tp$ is the number of true positives and $fn$ the number of false negatives. The recall is intuitively the ability of the classifier to find all the positive samples.\n",
    "* [f1-score](https://en.wikipedia.org/wiki/F1_score): a weighted average of the precision and recall, where an $F_1$ score reaches its best value at 1 and worst score at 0. The relative contribution of precision and recall to the $F_1$ score are equal. The formula for the $F_1$ score is: $F_1 = 2\\cdot\\frac{precision \\cdot recall}{precision + recall}$\n",
    "* support: the support is the number of occurrences of each class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "expected = y_test\n",
    "predicted = net.predict(X_test)\n",
    "print(metrics.classification_report(expected, predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion matrix\n",
    "\n",
    "The [`confusion_matrix`](http://scikit-learn.org/stable/modules/model_evaluation.html#confusion-matrix) function evaluates classification accuracy by computing the [confusion matrix](https://en.wikipedia.org/wiki/Confusion_matrix).\n",
    "\n",
    "By definition, a confusion matrix $C$ is such that $C_{i, j}$ is equal to the number of observations known to be in group $i$ but predicted to be in group $j$. Thus an optimal classification result would produce a diagonal matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(metrics.confusion_matrix(expected, predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training curve\n",
    "\n",
    "Number of iterations during training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "net.n_iter_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loss curve: (currently, [MLPClassifier](http://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html#sklearn.neural_network.MLPClassifier) supports only the [Cross-Entropy loss function](https://en.wikipedia.org/wiki/Cross_entropy#Cross-entropy_error_function_and_logistic_regression))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.plot(net.loss_curve_);\n",
    "plt.xlabel('Iterations');\n",
    "plt.ylabel('Loss');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Samples of predictions\n",
    "\n",
    "You can visualize the target and prediction for a few images of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "images_and_predictions = list(zip(X_test, predicted))\n",
    "for index, (image, prediction) in enumerate(images_and_predictions[:8]):\n",
    "    plt.subplot(2, 4, index+1)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(image.reshape((8,8)), cmap=plt.cm.gray_r, interpolation='nearest')\n",
    "    plt.title('Target: %i\\nPrediction: %i' % (y_test[index],prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the dataset, scaler and the network into files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "joblib.dump(scaler, 'digits_scaler.pkl') \n",
    "joblib.dump(net, 'digits_net.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can check the files of your scaler and network with [this notebook](mlp_digits_check.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Can the network do better?\n",
    "\n",
    "Re-train the network several times with the same dataset, and check what is the highest value for the percentage of correct classification. You may increase the number of hidden neurons, or even use two hidden layers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shuffling the dataset\n",
    "\n",
    "You may have noticed in the previous example, that splitting the dataset differently may lead to slightly different classification results.\n",
    "\n",
    "In order to better measure such results, you are going to test your network with **100** different test sets extracted from the dataset. For each iteration, you will compute the score of the **same** network with a **different** test set, and store the values in a list. Finally, you will compute the **mean and standard deviation** from the values in the list.\n",
    "\n",
    "<img src=\"img/present_gift_bonus_prize-128.png\" width=\"32\" align=\"left\" style=\"margin: 0px 20px\"> **BONUS**: we will set up a webpage for submitting the mean and std: the MLP with better classification performance will receive an extra bonus!!! \n",
    "\n",
    "#### Create a new notebook with the following statements:\n",
    "\n",
    "* Load your scaler and network files\n",
    "* Load the digits dataset\n",
    "* Iterate 100 times:\n",
    "  * Generate a new test set\n",
    "  * Compute the net score\n",
    "* Compute the mean and standard deviation of the values\n",
    "* Print the result\n",
    "\n",
    "**REMEMBER**: for the **workshop of sessions 2-3** you will submit the <tt>pkl</tt> files for the scaler and neural network that solves the digits problem, and the <tt>ipynb</tt> file with the 100-iteration loop for computing the average net score. "
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
