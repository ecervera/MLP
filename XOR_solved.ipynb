{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning the XOR function with a multilayer perceptron\n",
    "\n",
    "[<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/4/46/Colored_neural_network.svg/199px-Colored_neural_network.svg.png\" align=\"right\">](https://en.wikipedia.org/wiki/Multilayer_perceptron)\n",
    "\n",
    "*From Wikipedia, the free encyclopedia*\n",
    "\n",
    "A [multilayer perceptron](https://en.wikipedia.org/wiki/Multilayer_perceptron) (MLP) is a feedforward artificial neural network model that maps sets of input data onto a set of appropriate outputs. An MLP consists of multiple layers of nodes in a directed graph, with each layer fully connected to the next one. Except for the input nodes, each node is a neuron (or processing element) with a nonlinear activation function. MLP utilizes a supervised learning technique called backpropagation for training the network. MLP is a modification of the standard linear perceptron and can distinguish data that are not linearly separable.\n",
    "\n",
    "Consequently, MLP can outperform the perceptron and solve the XOR problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from packages.plot import plot_decision_boundary, plot_data\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load in the data\n",
    "\n",
    "This is the data for the truth table of the XOR function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = np.array([[0.,0.],\\\n",
    "              [0.,1.],\\\n",
    "              [1.,0.],\\\n",
    "              [1.,1.]])\n",
    "y = np.array([0.,1.,1.,0.])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the model\n",
    "\n",
    "Create a [MLP object](http://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html) with the following arguments:\n",
    "* [stochastic gradient descent](https://en.wikipedia.org/wiki/Stochastic_gradient_descent) solver (standard technique in [backpropagation](https://en.wikipedia.org/wiki/Backpropagation))\n",
    "* one hidden layer with 5 neurons\n",
    "* 4000 iterations maximum\n",
    "\n",
    "The rest of the arguments are set to their default values ([see documentation](http://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "net = MLPClassifier(solver='sgd',\\\n",
    "                    hidden_layer_sizes=(5, ),\\\n",
    "                    max_iter=4000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train\n",
    "\n",
    "The `fit` function automatically iterates until convergence or the maximum number of iterations is reached, so you only need to execute the following cell once. When the loss or score is not improving by at least *tol* (default 1e-4) for two consecutive iterations, convergence is considered to be reached and training stops."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "net.fit(x,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot the data\n",
    "\n",
    "The following figure displays the XOR data and the decision boundary of the MLP. This boundary is not linear anymore: it is represented in colors, so that the blue region in the plane corresponds to the features that are classified as 0's and consequently the brown region is classified as 1's."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_decision_boundary(net,x,y)\n",
    "plot_data(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Success or failure?\n",
    "\n",
    "There is not a unique solution to this problem. The figure below depicts some possible solutions:\n",
    "\n",
    "<table border=\"0\">\n",
    "<tr><td>\n",
    "<img src=\"img/xor_1.png\" width=200>\n",
    "</td><td>\n",
    "<img src=\"img/xor_2.png\" width=200>\n",
    "</td><td>\n",
    "<img src=\"img/xor_3.png\" width=200>\n",
    "</td></tr><tr><td>\n",
    "<img src=\"img/xor_4.png\" width=200>\n",
    "</td><td>\n",
    "<img src=\"img/xor_5.png\" width=200>\n",
    "</td><td>\n",
    "<img src=\"img/xor_6.png\" width=200>\n",
    "</td></tr>\n",
    "</table>\n",
    "\n",
    "However, the network may **not** converge. Sometimes, it can get stuck in a local minima. The algorithm stops but the result is not correct at all. For example:\n",
    "\n",
    "<table border=\"0\">\n",
    "<tr><td>\n",
    "<img src=\"img/xor_fail_1.png\" width=200>\n",
    "</td><td>\n",
    "<img src=\"img/xor_fail_2.png\" width=200>\n",
    "</td><td>\n",
    "<img src=\"img/xor_fail_3.png\" width=200>\n",
    "</td></tr>\n",
    "</table>\n",
    "\n",
    "Check the result of your network. You should find at least one convergent network, and one non-converging network. Then use the code below for saving each of the networks into a separate file. The networks can later be loaded and analysed without need of training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Non-converging network\n",
    "\n",
    "Percentage of correct classification of the training data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "net.score(x,y) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number of iterations during training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "net.n_iter_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loss curve: (currently, [MLPClassifier](http://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html#sklearn.neural_network.MLPClassifier) supports only the [Cross-Entropy loss function](https://en.wikipedia.org/wiki/Cross_entropy#Cross-entropy_error_function_and_logistic_regression))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.plot(net.loss_curve_);\n",
    "plt.xlabel('Iterations');\n",
    "plt.ylabel('Loss');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the network into a file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "joblib.dump(net, 'xor_non_converging.pkl') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converged network\n",
    "\n",
    "Percentage of correct classification of the training data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "net.score(x,y) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number of iterations during training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "net.n_iter_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loss curve: (currently, [MLPClassifier](http://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html#sklearn.neural_network.MLPClassifier) supports only the [Cross-Entropy loss function](https://en.wikipedia.org/wiki/Cross_entropy#Cross-entropy_error_function_and_logistic_regression))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.plot(net.loss_curve_);\n",
    "plt.xlabel('Iterations');\n",
    "plt.ylabel('Loss');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the network into a file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "joblib.dump(net, 'xor_converged.pkl') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should now check the saved files in [this notebook](XOR_checked.ipynb)."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
